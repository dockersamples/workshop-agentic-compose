models:
  gemma3:
    model: ai/gemma3-qat

services:
  workspace:
    image: michaelirwin244/workshop-environment
    pull_policy: always
    command: /home/coder/project
    ports:
      - 8085:8085
      - 6274:6274 # Used by MCP Inspector
      - 6277:6277 # Used by MCP Inspector
      - 3030:3030 # Used in agentic app running
      - 4111:4111 # Used in agentic app running (by Mastra)
    # use_api_socket: true
    volumes:
      - ./:/home/coder/project
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      MODEL_RUNNER_HOST: http://model-runner.docker.internal
      OPENAI_BASE_URL: http://model-runner.docker.internal/engines/v1
      OPENAI_API_KEY: not-required
      OPENAI_MODEL: ai/gemma3-qat
      MCPGATEWAY_ENDPOINT: http://mcp-gateway:8811/sse
    post_start:
      - command: chown 1000:1000 /var/run/docker.sock
        user: root

  visual-chatbot:
    image: mikesir87/visual-chatbot
    use_api_socket: true
    ports:
      - 3000:3000
    models:
      gemma3:
        endpoint_var: OPENAI_BASE_URL
        model_var: OPENAI_MODEL

volumes:
  project:

networks:
  default:
    name: workshop